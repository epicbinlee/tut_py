{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 导包"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2f3b8aa4e3b89b40"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ],
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2023-12-16T19:25:31.615996500Z",
     "start_time": "2023-12-16T19:25:31.576105100Z"
    }
   },
   "id": "initial_id"
  },
  {
   "cell_type": "markdown",
   "id": "e214519e5fa8ae99",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 读取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3f91272f994f392f",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-16T19:25:31.709745200Z",
     "start_time": "2023-12-16T19:25:31.582087300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 12) (418, 11) (418, 2)\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv(r'./datasets/train.csv')\n",
    "test_df = pd.read_csv(r'./datasets/test.csv')\n",
    "gender_df = pd.read_csv(r'./datasets/gender_submission.csv')\n",
    "print(train_df.shape, test_df.shape, gender_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806f6cacb1e24ba",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 查看"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4a350bb978cc4a42",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-16T19:25:31.710742700Z",
     "start_time": "2023-12-16T19:25:31.598044800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId      int64\n",
      "Survived         int64\n",
      "Pclass           int64\n",
      "Name            object\n",
      "Sex             object\n",
      "Age            float64\n",
      "SibSp            int64\n",
      "Parch            int64\n",
      "Ticket          object\n",
      "Fare           float64\n",
      "Cabin           object\n",
      "Embarked        object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(train_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1ead24fc6ac58e04",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-16T19:25:31.711740600Z",
     "start_time": "2023-12-16T19:25:31.614002200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId      int64\n",
      "Pclass           int64\n",
      "Name            object\n",
      "Sex             object\n",
      "Age            float64\n",
      "SibSp            int64\n",
      "Parch            int64\n",
      "Ticket          object\n",
      "Fare           float64\n",
      "Cabin           object\n",
      "Embarked        object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(test_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6d3c7f5f8b5c441b",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-16T19:25:31.711740600Z",
     "start_time": "2023-12-16T19:25:31.629960400Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "PassengerId    int64\nSurvived       int64\ndtype: object"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gender_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bf3b5028e7ef6124",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-16T19:25:31.732685900Z",
     "start_time": "2023-12-16T19:25:31.643921800Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "       PassengerId    Survived      Pclass         Age       SibSp  \\\ncount   891.000000  891.000000  891.000000  714.000000  891.000000   \nmean    446.000000    0.383838    2.308642   29.699118    0.523008   \nstd     257.353842    0.486592    0.836071   14.526497    1.102743   \nmin       1.000000    0.000000    1.000000    0.420000    0.000000   \n25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n75%     668.500000    1.000000    3.000000   38.000000    1.000000   \nmax     891.000000    1.000000    3.000000   80.000000    8.000000   \n\n            Parch        Fare  \ncount  891.000000  891.000000  \nmean     0.381594   32.204208  \nstd      0.806057   49.693429  \nmin      0.000000    0.000000  \n25%      0.000000    7.910400  \n50%      0.000000   14.454200  \n75%      0.000000   31.000000  \nmax      6.000000  512.329200  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Fare</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>891.000000</td>\n      <td>891.000000</td>\n      <td>891.000000</td>\n      <td>714.000000</td>\n      <td>891.000000</td>\n      <td>891.000000</td>\n      <td>891.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>446.000000</td>\n      <td>0.383838</td>\n      <td>2.308642</td>\n      <td>29.699118</td>\n      <td>0.523008</td>\n      <td>0.381594</td>\n      <td>32.204208</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>257.353842</td>\n      <td>0.486592</td>\n      <td>0.836071</td>\n      <td>14.526497</td>\n      <td>1.102743</td>\n      <td>0.806057</td>\n      <td>49.693429</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.420000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>223.500000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>20.125000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>7.910400</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>446.000000</td>\n      <td>0.000000</td>\n      <td>3.000000</td>\n      <td>28.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>14.454200</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>668.500000</td>\n      <td>1.000000</td>\n      <td>3.000000</td>\n      <td>38.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>31.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>891.000000</td>\n      <td>1.000000</td>\n      <td>3.000000</td>\n      <td>80.000000</td>\n      <td>8.000000</td>\n      <td>6.000000</td>\n      <td>512.329200</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25bcb8159b07fdd7",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 缺失"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5220a43fb083b8b0",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-16T19:25:31.732685900Z",
     "start_time": "2023-12-16T19:25:31.676834400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId      0\n",
      "Survived         0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age            177\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             0\n",
      "Cabin          687\n",
      "Embarked         2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1e95bb2cf22e87e4",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-16T19:25:31.732685900Z",
     "start_time": "2023-12-16T19:25:31.693789500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId    0\n",
      "Survived       0\n",
      "Pclass         0\n",
      "Name           0\n",
      "Sex            0\n",
      "Age            0\n",
      "SibSp          0\n",
      "Parch          0\n",
      "Ticket         0\n",
      "Fare           0\n",
      "Cabin          0\n",
      "Embarked       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 数值类型, 使用均值填充\n",
    "train_df['Age'].fillna(train_df['Age'].mean(), inplace=True)\n",
    "# 字符串类型，使用未知填充\n",
    "train_df['Cabin'].fillna('Unknown', inplace=True)\n",
    "# 字符串类型，使用未知填充\n",
    "train_df['Embarked'].fillna(train_df['Embarked'].mode()[0], inplace=True)\n",
    "# 查看空值\n",
    "print(train_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b9441792d7f673",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 特征工程"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b5af444040a2a2",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 特征工程\n",
    "\n",
    "如果你的特征只有几个离散的类别，而不是一个大的类别集，那么选择哪种方式通常取决于你的数据和机器学习模型的性质。以下是对三种方式的简要比较：\n",
    "\n",
    "1. **LabelEncoder:**\n",
    "   - **优点：** 简单，不引入高维度。适用于有序的类别。\n",
    "   - **注意：** 只适合于有序的类别，因为它会为每个类别分配一个整数标签，模型可能会误以为这些整数之间存在某种有序关系。\n",
    "\n",
    "   ```python\n",
    "   from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "   label_encoder = LabelEncoder()\n",
    "   train_df['Category'] = label_encoder.fit_transform(train_df['Category'])\n",
    "   ```\n",
    "\n",
    "2. **get_dummies:**\n",
    "   - **优点：** 适用于无序的、离散的类别。为每个类别创建一个新的二进制列，不引入假设类别之间有序的信息。\n",
    "   - **缺点：** 可能引入高维度，但对于几个类型的特征通常是可接受的。\n",
    "\n",
    "   ```python\n",
    "   category_dummies = pd.get_dummies(train_df['Category'], prefix='Category')\n",
    "   train_df = pd.concat([train_df, category_dummies], axis=1)\n",
    "   ```\n",
    "\n",
    "3. **map:**\n",
    "   - **优点：** 可以手动指定映射，更加灵活。适用于有序或无序的类别。\n",
    "   - **缺点：** 需要提前定义映射字典，可能需要对数据进行额外的处理。\n",
    "\n",
    "   ```python\n",
    "   category_mapping = {'A': 0, 'B': 1, 'C': 2}\n",
    "   train_df['Category'] = train_df['Category'].map(category_mapping)\n",
    "   ```\n",
    "\n",
    "如果你的特征只有几个类型，而且这些类型之间没有明显的有序关系，通常可以优先考虑使用 `get_dummies` 或 `map`。`get_dummies` 会为每个类别创建一个独热编码列，而 `map` 允许你手动指定映射关系。在这种情况下，选择哪一种通常取决于你更喜欢使用哪种方式，并且哪一种方式更符合你对数据的理解。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6983bfea1f333e9f",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-16T19:25:31.735677800Z",
     "start_time": "2023-12-16T19:25:31.708749100Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0                              Braund, Mr. Owen Harris\n1    Cumings, Mrs. John Bradley (Florence Briggs Th...\n2                               Heikkinen, Miss. Laina\n3         Futrelle, Mrs. Jacques Heath (Lily May Peel)\n4                             Allen, Mr. William Henry\nName: Name, dtype: object"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['Name'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2f47425811e00ed4",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-16T19:25:31.799514600Z",
     "start_time": "2023-12-16T19:25:31.725703600Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "    LastName Title  NameLength\n0     Braund    Mr          23\n1    Cumings   Mrs          51\n2  Heikkinen  Miss          22",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>LastName</th>\n      <th>Title</th>\n      <th>NameLength</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Braund</td>\n      <td>Mr</td>\n      <td>23</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Cumings</td>\n      <td>Mrs</td>\n      <td>51</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Heikkinen</td>\n      <td>Miss</td>\n      <td>22</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# name特征\n",
    "train_df['LastName'] = train_df['Name'].apply(lambda x: x.split(',')[0])\n",
    "train_df['Title'] = train_df['Name'].apply(lambda x: re.search(' ([A-Za-z]+)\\.', x).group(1))\n",
    "train_df['NameLength'] = train_df['Name'].apply(len)\n",
    "train_df[['LastName', 'Title', 'NameLength']].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7e3499057de8b360",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-16T19:25:31.842399100Z",
     "start_time": "2023-12-16T19:25:31.747644700Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   LastName  Title  NameLength\n0        73     12          23\n1       136     13          51\n2       251      9          22",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>LastName</th>\n      <th>Title</th>\n      <th>NameLength</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>73</td>\n      <td>12</td>\n      <td>23</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>136</td>\n      <td>13</td>\n      <td>51</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>251</td>\n      <td>9</td>\n      <td>22</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "train_df['LastName'] = label_encoder.fit_transform(train_df['LastName'])\n",
    "train_df['Title'] = label_encoder.fit_transform(train_df['Title'])\n",
    "train_df['Cabin'] = label_encoder.fit_transform(train_df['Cabin'])\n",
    "\n",
    "train_df[['LastName', 'Title', 'NameLength']].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b7b92ed914dc1412",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-16T19:25:31.869879400Z",
     "start_time": "2023-12-16T19:25:31.757620300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   PassengerId  Survived  Pclass  \\\n0            1         0       3   \n1            2         1       1   \n2            3         1       3   \n\n                                                Name     Sex   Age  SibSp  \\\n0                            Braund, Mr. Owen Harris    male  22.0      1   \n1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n2                             Heikkinen, Miss. Laina  female  26.0      0   \n\n   Parch            Ticket     Fare  Cabin Embarked  LastName  Title  \\\n0      0         A/5 21171   7.2500    147        S        73     12   \n1      0          PC 17599  71.2833     81        C       136     13   \n2      0  STON/O2. 3101282   7.9250    147        S       251      9   \n\n   NameLength  \n0          23  \n1          51  \n2          22  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n      <th>LastName</th>\n      <th>Title</th>\n      <th>NameLength</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Braund, Mr. Owen Harris</td>\n      <td>male</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>A/5 21171</td>\n      <td>7.2500</td>\n      <td>147</td>\n      <td>S</td>\n      <td>73</td>\n      <td>12</td>\n      <td>23</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n      <td>female</td>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>PC 17599</td>\n      <td>71.2833</td>\n      <td>81</td>\n      <td>C</td>\n      <td>136</td>\n      <td>13</td>\n      <td>51</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n      <td>3</td>\n      <td>Heikkinen, Miss. Laina</td>\n      <td>female</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>STON/O2. 3101282</td>\n      <td>7.9250</td>\n      <td>147</td>\n      <td>S</td>\n      <td>251</td>\n      <td>9</td>\n      <td>22</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sex、Embarked特征\n",
    "train_df['Sex'] = train_df['Sex'].astype('category')\n",
    "train_df['Embarked'] = train_df['Embarked'].astype('category')\n",
    "train_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 训练数据"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "748c0835c013ecd4"
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e5da1f4f2bed0ede",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-16T19:25:31.870875900Z",
     "start_time": "2023-12-16T19:25:31.774573300Z"
    }
   },
   "outputs": [],
   "source": [
    "# 将数据分割为特征矩阵和目标变量\n",
    "X = train_df[['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Cabin', 'Embarked', 'LastName', 'Title', 'NameLength']]\n",
    "y = train_df['Survived']\n",
    "\n",
    "# 将数据划分为训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 创建LightGBM数据集\n",
    "train_data = lgb.Dataset(X_train, label=y_train, categorical_feature=['Sex', 'Embarked'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "## 训练过程"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-16T19:25:31.870875900Z",
     "start_time": "2023-12-16T19:25:31.788536300Z"
    }
   },
   "id": "af6e91484aa2735b"
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d09b77cede7bac2f",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-16T19:25:31.931713200Z",
     "start_time": "2023-12-16T19:25:31.804502300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 268, number of negative: 444\n",
      "[LightGBM] [Debug] Dataset::GetMultiBinFromSparseFeatures: sparse rate 0.739466\n",
      "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.301966\n",
      "[LightGBM] [Debug] init for col-wise cost 0.000104 seconds, init for row-wise cost 0.000231 seconds\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000280 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 538\n",
      "[LightGBM] [Info] Number of data points in the train set: 712, number of used features: 11\n",
      "[LightGBM] [Debug] Use subset for bagging\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.376404 -> initscore=-0.504838\n",
      "[LightGBM] [Info] Start training from score -0.504838\n",
      "[LightGBM] [Debug] Re-bagging, using 575 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 15 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 15 and depth = 6\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 15 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 15 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 15 and depth = 7\n",
      "[LightGBM] [Debug] Re-bagging, using 570 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 15 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 15 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 15 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 15 and depth = 6\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 15 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 574 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 15 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 15 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 15 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 15 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 15 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 561 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 15 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 15 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 15 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 15 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 15 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 555 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 15 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 15 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 15 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 15 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 15 and depth = 8\n",
      "[LightGBM] [Debug] Re-bagging, using 575 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 15 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 15 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 15 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 15 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 15 and depth = 7\n",
      "[LightGBM] [Debug] Re-bagging, using 544 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 15 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 15 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 15 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 15 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 15 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 573 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 15 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 15 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 15 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 15 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 15 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 578 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 15 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 15 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 15 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 15 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 15 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 576 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 15 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 15 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 15 and depth = 6\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 15 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 15 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 558 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 15 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 15 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 15 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 15 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 15 and depth = 7\n",
      "[LightGBM] [Debug] Re-bagging, using 579 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 15 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 15 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 15 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 15 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 15 and depth = 8\n",
      "[LightGBM] [Debug] Re-bagging, using 578 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 15 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 15 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 15 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 15 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 15 and depth = 7\n",
      "[LightGBM] [Debug] Re-bagging, using 584 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 15 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 15 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 15 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 15 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 15 and depth = 7\n",
      "[LightGBM] [Debug] Re-bagging, using 559 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 15 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 15 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 15 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 15 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 15 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 569 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 15 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 15 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 15 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 15 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 15 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 550 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 15 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 15 and depth = 6\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 15 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 15 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 15 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 560 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 15 and depth = 6\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 15 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 15 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 15 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 15 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 569 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 15 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 15 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 15 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 15 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 15 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 588 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 15 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 15 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 15 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 15 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 15 and depth = 8\n",
      "Accuracy: 0.8435754189944135\n"
     ]
    }
   ],
   "source": [
    "# 定义 LightGBM 模型训练参数\n",
    "\n",
    "params = {\n",
    "    \"objective\": \"binary\",  # 优化目标：二分类问题\n",
    "    \"metric\": \"binary_logloss\",  # 评估指标：二分类错误率\n",
    "    \"boosting_type\": \"gbdt\",  # 使用梯度提升树算法\n",
    "    \"num_leaves\": 15,  # 每棵树的最大叶子节点数，控制树的复杂度\n",
    "    \"learning_rate\": 0.1,  # 学习率，控制每一步迭代中模型参数的调整幅度\n",
    "    \"feature_fraction\": 0.8,  # 每次迭代中随机选择特征的比例，防止过拟合\n",
    "    \"bagging_fraction\": 0.8,  # 每次迭代中随机选择数据的比例，防止过拟合\n",
    "    \"bagging_freq\": 5,  # 多少次迭代进行 bagging，增加模型的多样性\n",
    "    \"verbose\": 2  # 控制训练过程的输出信息详细程度，设置为 2 可以提供相对详细的训练信息\n",
    "}\n",
    "\n",
    "# 应用场景和指导：\n",
    "# - \"objective\": 通常根据具体问题选择适当的目标，对于二分类问题，使用 \"binary\"。\n",
    "# - \"metric\": 选择与问题相适应的评估指标，\"binary_error\" 用于二分类问题的错误率。\n",
    "# - \"boosting_type\": 根据数据和问题选择合适的 boosting 类型，\"gbdt\" 是一种常见的选择。\n",
    "# - \"num_leaves\": 调整树的复杂度，较小的值有助于防止过拟合，但可能降低模型拟合能力。\n",
    "# - \"learning_rate\": 学习率的选择影响模型收敛速度，过大可能导致震荡，过小可能需要更多迭代。\n",
    "# - \"feature_fraction\" 和 \"bagging_fraction\": 控制每次迭代中随机选择特征和数据的比例，防止过拟合。\n",
    "# - \"bagging_freq\": 控制 bagging 的频率，增加模型的多样性，通常选择一个适中的值。\n",
    "# - \"verbose\": 控制训练过程的输出信息，调试阶段设置较大的值，生产环境设置较小的值或为 0。\n",
    "\n",
    "\n",
    "# 将测试集作为验证集\n",
    "valid_data = lgb.Dataset(X_test, label=y_test)\n",
    "valid_sets = [valid_data]\n",
    "\n",
    "model = lgb.train(params, train_data, num_boost_round=100, valid_sets=valid_sets, valid_names=[\"validation\"])\n",
    "\n",
    "# 在测试集上进行预测\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_binary = [1 if p >= 0.5 else 0 for p in y_pred]\n",
    "\n",
    "# 计算准确率\n",
    "accuracy = accuracy_score(y_test, y_pred_binary)\n",
    "print(f'Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 梯度提升树说明\n",
    "是不是简单可以理解为嗯决策树增长的过程，比如说当前这一轮决策的过程中，它只生成了当前这一轮的增长，那么这么就这就叫一个弱模型。那所谓集成学习就是将这些每一轮的增长叠加起来，然后构成了一个大的树。这就是基层学习的过程对吗？\n",
    "\n",
    "ChatGPT\n",
    "你的理解基本正确，梯度提升的确可以用决策树的增长过程来解释。让我们再强调一下：\n",
    "\n",
    "弱模型的生成： 在每一轮梯度提升中，弱模型通常是决策树。这棵决策树是为了捕捉当前模型无法很好拟合的模式，它只是对数据进行了一部分的拟合，因此被称为弱学习器。\n",
    "\n",
    "集成学习的过程： 每一轮的弱模型都在尝试修正上一轮模型的预测误差，而整体模型就是将每一轮的弱模型组合起来的结果。这个组合可以是简单的加法（对回归问题），也可以是一种加权的组合。最终，整体模型的预测是通过将每个弱模型的输出相加而得到的。\n",
    "\n",
    "基层学习的概念： 在梯度提升中，这种逐轮生成弱模型、每轮弱模型只能拟合一部分模式、然后集成所有弱模型的过程可以被看作是一种基层学习。基层学习强调的是通过多次迭代，每次迭代生成一个弱模型，并通过集成来提升整体模型性能的过程。\n",
    "\n",
    "所以，你可以将梯度提升看作是基层学习的一种实现方式，通过逐步修正预测误差，每一轮生成一个弱模型，最终构成一个强大的集成模型。这种集成学习的思想也是梯度提升的核心。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1b5f7b60911ace1c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_prompt_df = pd.read_csv(r'./datasets/train_prompts.csv')\n",
    "train_essays_df = pd.read_csv(r'./datasets/train_essays.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "6189791bf982924d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_prompt_df.iloc[0]"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "151013ca15416997"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_essays_df.iloc[0]"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "86071c926dcf9032"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import wandb\n",
    "import random\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import plotly.io as pio\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "from torch.optim import AdamW\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from transformers import AutoTokenizer, AutoConfig, AutoModel, get_linear_schedule_with_warmup\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "# Set global template and layout colors\n",
    "# 设置默认的图表模板为 \"plotly_dark\"\n",
    "pio.templates.default = \"plotly_dark\"\n",
    "# 设置图表的纸张背景颜色为深灰色 (#1F1F1F)\n",
    "pio.templates[pio.templates.default].layout['paper_bgcolor'] = '#1F1F1F'\n",
    "# 设置图表的绘图区域背景颜色为深灰色 (#1F1F1F)\n",
    "pio.templates[pio.templates.default].layout['plot_bgcolor'] = '#1F1F1F'\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "9d2abec889c339af"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 定义一个名为 CONFIG 的类，用于存储配置参数\n",
    "class CONFIG:\n",
    "    # 随机种子，用于重现实验结果\n",
    "    seed = 300\n",
    "    # 折数，用于交叉验证\n",
    "    num_fold = 3\n",
    "    # 使用的预训练模型名称\n",
    "    model = 'roberta-base'\n",
    "    # 文本序列的最大长度\n",
    "    max_len = 512\n",
    "    # 训练时的批量大小\n",
    "    train_batch_size = 16\n",
    "    # 验证时的批量大小\n",
    "    valid_batch_size = 16\n",
    "    # 训练轮数（epochs）\n",
    "    epochs = 2\n",
    "    # 学习率\n",
    "    learning_rate = 1e-5\n",
    "    # 学习率调度器类型\n",
    "    scheduler = 'linear'\n",
    "    # 设备类型，如果可用 CUDA，则使用 'cuda'，否则使用 'cpu'\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    # 使用预训练模型的 tokenizer 来处理文本数据\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model)\n",
    "\n",
    "\n",
    "# 将 tokenizer 保存到指定目录（'./tokenizer/'）\n",
    "CONFIG.tokenizer.save_pretrained('./tokenizer/')"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "a482ea480ff88428"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "153d8b3e1376066c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#返回cuda表示成功\n",
    "#或者\n",
    "print(torch.cuda.is_available())\n",
    "#返回True表示成功\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "ca387f7b098b26cc"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "\n",
    "seed_everything(CONFIG.seed)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "58e4d38c6d3ea797"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "a77dff3231b3ff19"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "9434c62a14f265cb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "9a2416de7a08b255"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "466c7eade95c0b6e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "6acf68a60072ad99"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "5bce7bcc7e198518"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "c8f4e756990465a0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "887a96913a92ece7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "ce94d45bb189ab0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "58133a27f17a7888"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
